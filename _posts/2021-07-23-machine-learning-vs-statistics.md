---
title: "关于「机器学习和统计学的区别」的思考"
date: 2021-07-23 15:40:18 +0900
category: machine learning
---

在自学/整理机器学习的时候, 我逐步地发现: 对于同样一个问题, 经常出现既有统计学的解释, 也有机器学习的解释的情况. 对于我个人来说, 很多时候会把两种解释, 两套名词混在一起, 导致逻辑不清晰, 甚至出错的情况. 并且我发现好像有部分人也和我有同样的困惑. 在查阅各种资料之后, 终于这篇文章 [The Actual Difference between Statics and Machine Learning](https://towardsdatascience.com/the-actual-difference-between-statistics-and-machine-learning-64b49f07ea3) 解决了我很多困惑. 因此我总结了一些自己看完文章之后的一些复盘还有思考.

# 文章内容回味

首先大概总结一下文章中的核心观点. 文章拿线性回归举了一个简单的列子. 首先, 线性回归本身是一种分析自变量与因变量之间关系的统计方法. 通过这个方法, 我们既可以**训练一个线性回归器**(Linear Regressor), 也可以通过最小二乘法**拟合一个统计回归模型**.

**训练线性回归器**做的事情是 “训练模型”, 这个过程只用到了数据的一部分, 也就是训练数据集(Train Dataset). 而训练得到的模型的性能则需要通过数据的另一部分, 也就是测试数据集(Test Dataset), 进行模型的精度评价. 所以机器学习的最终的目的是获得一个“在测试集上能够表现最佳”的模型. 在那之后可能会使用这个模型去预测未来新的数据.

而**拟合统计模型**的目的是“建立模型”, 这个过程是不需要训练集和测试集的. 而建模的目的是为了描述特征量数据和目标变量之间的关系, 并不是为了预测未来的数据. 这个过程我们称之为**统计推断(Statistical Inference)**. **虽然建立的模型可以用来预测, 但是预测不是目的**. 同时, 评价模型的方法也不再是使用测试集, 而是采用统计学中常出现的参数的显著性和健壮性进行评价.

上述两者放在一起说: 机器学习的目的是获得一个可以预测未来的模型, 而很少关心该模型的可解释性.换句话说, 就是成果主义. 我们只关心你这个模型能不能预测地准确未知数据. 再换句话说, 只要预测地准确, 我们甚至毫不关心模型能否写成容易理解地数学表达式 (涉及到神经网络的时候, 也确实没有办法写成表达式, 是一个完全的黑盒子). 而统计推断更在乎的是寻找出藏在数据之后的变量之间的关系. 只是掌握了这个内在关系之后, 恰好可以用其来预测而已.

# 个人体验

总结上述的内容就是:

>  统计模型是为了推理而设计, 而机器学习是为了获得准确的预测.

确实在学习初期可能并不明白这句话到底在说什么, 但是越在工作中使用机器学习和统计学越能感觉到这句话很对. 

我本人的工作会涉及到生产环节的质量保证. 为了找到影响一个产品正品率的影响因素, 我需要收集生产过程中大量的数据, 比如环境温度, 湿度, 治具表面温度, 化学反应时间等等, 大大小小的生产过程总共有上百个特征量. 一个最理想的状态, 我当然希望能够找到一个可解释的模型, 比如:

$$
Q=k_1\times温度+k_2\times湿度+k_3\times表面温度+k_4\times反应时间+\dots\notag
$$

也就是能够找到这里的系数 $(k_1, k_2, k_3,\dots)$.  通多各个特征量去预测一个产品是为正品的概率 $Q$. 根据上述的总结内容, 更适合采用拟合统计模型的方式去解决这样的问题. 得到每一个生产环节特征量对最终品质的影响程度, 就可以向工厂人员反映, 告诉他们哪些环节需要严格控制, 哪些环节影响不大. 总体的效果就是提高了工厂人员工作的效率以及提高了产品正品率. 可是实际上由于采集的数据过于庞大, 实际模型过于复杂, 很难用这么一个清晰而简单的统计模型去描述内在关系. 我们只能得到一个这样一个黑盒模型:

$$
Q=f(温度,适度,表面温度,反应时间,\dots\notag)
$$

之后我使用这个黑盒模型去预测一个产品是正品还是次品, 次品的话处理掉, 以保证最终出厂的都是正品. 能实现成这样效果就已经能够带了巨大的成本削减, 足够让人开心了, 也就没有太强烈的需求去搞清楚各个特征量和品质之间的关系到底如何了(还要什么自行车:joy:)

由此也引出了一个很重要的思考, 在确定启动一个课题之前, 一定要捋清楚「本课题最终的目的是什么」(统计推断还是结果预测), 以及「达到什么样的水平才能算完成」(模型参数显著性水平/置信区间或者是测试集预测正确率)这两个大问题. 不同的目的使得采用的手段不同, 不同的手段需要的知识体系很可能就不一样. 只有脑袋里对最终的目的很清晰, 才能让自己课题推进的过程中不至于混乱.

# 类似的困惑

在数据科学学习的初期, 相信大部分人和我一样, 对于AI/机器学习/深度学习/数据科学/统计学等名词的关系也产生过困惑. 这些名词的比较类似于上述的比较, 很多时候明白了其中的目的自然就能分清楚了.

首先 AI 或者叫人工智能, 目的是为了实现一个拥有人类智能的机器. 它是一个超大型的交叉学科, 这是毋庸置疑的. 按照 Wikipedia 给出的定义, AI 这个研究领域包括了一些子课题或者说分支: 演绎/推理/解决问题, 知识表示, 规划, 学习, 运动和控制, 知觉, 社交, 创造力, 伦理等等很多方面, 其中学习指的就是机器学习. 因此说机器学习是AI中的一部分或者说一个研究分支.

机器学习的主要目的是为了让机器从输入的数据中获得知识(也就是训练模型), 从而让机器自动地去判断和输出相应的结果(也就是预测). 机器学习中也会有各种各样不同的问题, 按照学习过程中是"否有反馈"这一属性, 可以分为监督学习(有反馈), 非监督学习(无反馈)以及强化学习(执行很多步骤之后有反馈). 为了解决大量的机器学习的问题, 前人的研究已经给出了很多效果很好的算法和模型, 包括了前面文章中介绍的[决策树模型]({% post_url 2020-11-02-summary-of-machine-learning-algorithms-decision-tree %})还有[线性回归模型]({% post_url 2021-07-17-summary-of-machine-learning-algorithms-linear-model-1 %}). 其中有一种被广泛使用的就是神经网络模型, 它是仿造人体的神经网络的算法, 也如人体神经一样是有"层"的概念的. 神经网络的层数越多, 称模型越深. 一般在图像处理, 自然语言处理领域神经网络都非常地深. 涉及到包含深层的神经网络的问题都可以使用深度学习来概括. 综上, 深度学习是机器学习的神经网络算法的一个特殊体现, 是其中的一个部分.

最后是数据科学. 其实如同这个名称的字面意思, 数据科学是紧扣数据的. 其目的最主要的是通过分析已有的数据, 得出一些事物背后的因果/相关关系, 或者做出一些对未来的预测, 以便给出下一步的决策. 为了实现这样的目的, 需要对数据进行预处理, 可视化, 寻找并学习出最适合模型或者对数据进行相关分析和因果推断. 最终将得出的结论反映或者共享于他人. 在这个过程中, 机器学习/统计学只是一种手段, 而不是目的. 并且有一点需要注意的是, 数据科学最重要的是**需要一定的专业领域知识(Domain Knowledge)**.

最终祭出我心中的, 描述 AI/机器学习/深度学习/数据科学/统计学之间关系的一张图(仅代表个人意见)

![关系图](https://raw.githubusercontent.com/simcookies/image-host/master/imgs/20210723145550.png)

# 追溯缘由

回到标题. 归根到底, 为什么会产生这样的混乱?  最开始产生这样的困惑是还是在线性回归里面. 传统的统计学基于均值方差, 利用线性代数理论一下子就计算得出了回归模型的各个参数. 并且这个计算过程没有其他的选择, 只有唯一的解, 不存在过拟合或者欠拟合的概念. 但是机器学习不一样, 我们使用均值方差作为损失函数, 需要调整模型的超参数, 使得模型在数据集上表现出最小的损失. 找到的那一组超参数碰巧(理论上当然不是碰巧)得到了和传统统计学一样的模型结果. 在这个过程中, 我们使用了梯度下降法, 超参数是不断变化的, 会有很多个解, 根据对数据的拟合的程度来分就自然有了过拟合和欠拟合.

正是因为两种方法最终得到一种模型, 自然就会让我们初学者怀疑: 我刚才干了什么? 统计推断出来的还是机器学习出来的? 尤其是现在 Scikit-Learn 这样现有的机器学习包, 帮我们做完所有的事. 会让我们更加模糊. 所以这也成了我非要将算法一个一个拆开看并整理出来的原因. 同时涉及到图像处理, 自然语言处理问题的时候, 就不是统计学建模能够解决的了, 这个时候机器学习和统计学的不同就能够深刻感受到了. (简单点说, 就是现在的模型太简单的原因 :joy: .)

# 结论

正如文章中所说, 两种方法本质都是基于统计学的. 在数据科学家的眼里, 更多偏向于模型拥有合理的解释, 所以统计学似乎成了更好的选择. 但是正如我在实际工作中遇到的问题那样, 在这个大数据时代, 统计学已经不能满足庞大数据的处理了, 这个时候机器学习就自然更适合了. 不过, 无论选择哪一个, 理清楚自己的目的, 再选择手段永远是最重要的.